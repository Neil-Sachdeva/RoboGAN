{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Robo_Master",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzzzs-unBM1",
        "colab_type": "text"
      },
      "source": [
        "## **Data Formatting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ZyhwZjm1BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUDrYr7im09m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import os\n",
        "os.chdir('gdrive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14-WNAwom01n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clip = cv2.VideoCapture(\"/content/drive/My Drive/data18/Training/Dataset1/Video.avi\")\n",
        "clip_L = cv2.VideoCapture(\"/content/drive/My Drive/data18/Training/Dataset1/Left_Instrument_Segmentation.avi\")\n",
        "clip_R = cv2.VideoCapture(\"/content/drive/My Drive/data18/Training/Dataset1/Right_Instrument_Segmentation.avi\")\n",
        "\n",
        "i = 0\n",
        "\n",
        "#Change the paths for the clips and the upload path\n",
        "path = \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix/datasets/ML_Data/%s/Robo_In_%4d.jpeg\"\n",
        "while clip.isOpened() and clip_L.isOpened() and clip_R.isOpened():\n",
        "    ret, frame = clip.read()\n",
        "    ret_L, frame_L = clip_L.read()\n",
        "    ret_R, frame_R = clip_R.read()\n",
        "    if ret and ret_L and ret_R:\n",
        "        frame_LR = np.sum((frame_L, frame_R), axis=0)\n",
        "        frame_cat = np.concatenate((frame, frame_LR), axis=1)\n",
        "        cv2.imwrite(path % (\"val\" if i > 885 else \"train\",i), frame_cat)\n",
        "        i += 1\n",
        "        del frame_LR\n",
        "        del frame_cat\n",
        "        if i % 50 == 0:\n",
        "            print(\"finished %d images\"%i)\n",
        "    else:\n",
        "        break\n",
        "    del ret\n",
        "    del ret_L\n",
        "    del ret_R\n",
        "    del frame\n",
        "    del frame_L\n",
        "    del frame_R\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ATWeWhmV01",
        "colab_type": "text"
      },
      "source": [
        "## **Pix2Pix Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I9OM1r9kx4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HYPERPARAMETERS##############################################################################\n",
        "data_dir = 'data18/Training/ML_Data/'\n",
        "git_dir = '/content/gdrive/My Drive/pytorch-CycleGAN-and-pix2pix'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwjREJkwmBhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHv9zcAqmLKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('python3 -m pip3 install visdom')\n",
        "get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')\n",
        "get_ipython().system_raw('ssh -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -R MPCR_Visdom:80:localhost:8097 serveo.net &')\n",
        "print('Visdom view: {}'.format('https://MPCR_Visdom.serveo.net/'))\n",
        "\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "!pip3 install scipy==1.1.0\n",
        "\n",
        "shutil.move((data_dir), (git_dir + '/datasets/'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvg4vvTcmQsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TRAINING/TESTING#############################################################################\n",
        "os.chdir(git_dir)\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8euYqPomTGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 train.py --dataroot ./datasets/ML_Data --name Robo_Surgery --model pix2pix\n",
        "!python3 test.py --dataroot ./datasets/ML_Data --name Robo_Surgery --model pix2pix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WTev54wbXuMC"
      },
      "source": [
        "## **Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVV2VkIlXyW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def scale(x):\n",
        "  \n",
        "  return (x-np.min(x))/(np.max(x))\n",
        "\n",
        "def plot(x):\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(scale(x), cmap = 'gray')\n",
        "    ax.axis('off')\n",
        "#     fig.set_size_inches(18, 10)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPc1QPdiX_vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/pytorch-CycleGAN-and-pix2pix/checkpoints/Robo_Surgery/web/images/\"\n",
        "fake1 = cv2.imread(path + \"epoch001_fake_B.png\")\n",
        "real1 = cv2.imread(path + \"epoch001_real_B.png\")\n",
        "fake200 = cv2.imread(path + \"epoch200_fake_B.png\")\n",
        "real200 = cv2.imread(path + \"epoch200_real_B.png\")\n",
        "diff1 = real1-fake1\n",
        "diff200 = real200-fake200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK-8VLcuYVKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(fake1)\n",
        "plot(real1)\n",
        "plot(diff1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbqdUw-OYXx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(fake200)\n",
        "plot(real200)\n",
        "plot(diff200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI47aKCpY2XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(diff1.flatten(),50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiiLJPmzY2QH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(diff200.flatten(),50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}